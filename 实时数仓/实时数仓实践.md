# 1 科杰大数据解决方案 - 基于Flink构建实时数仓

[link 基于Flink构建实时数仓](https://zhuanlan.zhihu.com/p/192789482)

Q1

1、 ODS层：以Kafka为支撑，将所有需要实时处理的相关数据放到Kafka队列中来实现贴源数据层；

2、 DWD层：实时计算订阅业务数据消息队列，然后通过数据清洗、多数据源join、流式数据与离线维度信息等的组合，将一些相同粒度的业务系统、维表中的维度属性全部关联到一起，增加数据易用性和复用性，得到最终的实时明细数据；
3、 DIM层：存放用于关联查询的维度信息，可以根据数据现状来选择存储介质，例如使用HBase或者Mysql

4、 DWS层：轻度汇总层是为了便于面向AdHoc查询或者Olap分析构建的轻度汇总结果集合，适合数据维度、指标信息比较多的情况，为了方便根据自定义条件的快速筛选和指标聚合，推荐使用MPP类型数据库进行存储，此层可视场景情况决定是否构建；

5、 APP层：面向实时数据场景需求构建的高度汇总层，可以根据不通的数据应用场景决定使用存储介质或者引擎；例如面向业务历史明细、BI支持等Olap分析场景，可以使用Druid、Greenplum，面向实时监控大屏、高并发汇总指标等需求，可以使用KV模式的HBase；数据量较小的时候，也可以使用Mysql来进行存储。

这里要注意下，其实APP层已经脱离了数仓，这里虽然作为了数仓的独立分层，但是实际APP层的数据已经分布存储在各种介质中用于使用。

Q2

我们在看看FlinkSql有哪些优势呢，我们从四方面去看；第一，支持 ANSI SQL 的标准；第二，丰富的数据类型与函数支持，包括常见的算术运算与聚合运算；第三，可自定义 Source/Sink，基于此可以灵活地扩展上下游；第四，使用SQL进行数据处理，技术门槛要低于Jar的开发，批流SQL可以进行有效的快速转换。

S3

推荐了其实施平台, 类似阿里的 Realtime. 

元数据管理, 基于WEB的IDE开发, 任务作业管理, 可视化集群大屏监控



# 2 基于 Flink + Hive 构建流批一体准实时数仓

https://developer.aliyun.com/article/774843

简单来说就是把 Kafka 表的元数据信息存储到 HiveMetaStore 中，做到离线和实时的表 Meta 的统一。

我们知道 Flink 是支持维表关联查询 MySQL 和 HBase 的，在计算中维护一个 LRU 的缓存，未命中查询 MySQL 或 HBase。但是没有 Lookup 的能力怎么办呢？数据一般是放在离线数仓中的，所以业务上我们一般采用 Hive Table 定期同步到 HBase 或者 MySQL。Flink 也可以允许直接维表关联 Hive 表，目前的实现很简单，需要在每个并发中全量 Load Hive 表的所有数据，只能针对小表的关联。



# 3 网易实时数仓

## 传统数仓和实时数仓对比  

传统数仓模型

![image-20200920090305198](https://strawberryamoszc.oss-cn-shanghai.aliyuncs.com/projects/rt/image-20200920090305198.png)

实时数仓模型

![image-20200920090216093](https://strawberryamoszc.oss-cn-shanghai.aliyuncs.com/projects/rtimage-20200920090216093.png)

实时数仓和传统数仓的对比主要可以从四个方面考虑：

1. 分层方式，离线数仓为了考虑到效率问题，一般会采取空间换时间的方式，层级划分会比较多；则实时数仓考虑到实时性问题，一般分层会比较少，另外也减少了中间流程出错的可能性。
2. 事实数据存储方面，离线数仓会基于 HDFS，实时数仓则会基于消息队列（如 Kafka）。
3. 维度数据存储，实时数仓会将数据放在 KV 存储上面。
4. 数据加工过程，离线数仓一般以 Hive、Spark 等批处理为主，而实时数仓则是基于实时计算引擎如 Storm、Flink 等，以流处理为主。



## 整体设计

整体设计如下图，基于业务系统的数据，数据模型采用中间层的设计理念，建设仓配实时数仓；计算引擎，选择更易用、性能表现更佳的实时计算作为主要的计算引擎；数据服务，选择天工数据服务中间件，避免直连数据库，且基于天工可以做到主备链路灵活配置秒级切换；数据应用，围绕大促全链路，从活动计划、活动备货、活动直播、活动售后、活动复盘五个维度，建设仓配大促数据体系。

![image-20200920101832011](https://strawberryamoszc.oss-cn-shanghai.aliyuncs.com/projects/rt/image-20200920101832011.png)

总结下，实时数仓主要有两个要点。首先是分层设计上，一般也是参考离线数仓的设计，通常会分为ODS操作数据层、DWD明细层、DWS汇总层以及ADS应用层，可能还会分出一层DIM维度数据层。另外分层设计上也有不同的思路，比如可以将DWS和ADS归为DM数据集市层，网易严选就是这样设计的。

技术选型上，离线数仓一般依托HDFS或Hive构建，选择MR或Spark计算引擎；实时数仓存储层更多是选择Kafka等消息引擎，通常明细层和汇总层都放在Kafka，计算层则多是选择Flink/Spark Streaming/Storm，这方面Flink更有优势，社区也更倾向于选择Flink。大概总结这么多，笔者才疏学浅，有不同看法的同学欢迎留言讨论。

![image-20200920090954134](https://strawberryamoszc.oss-cn-shanghai.aliyuncs.com/projects/rt/image-20200920090954134.png)



## 数据模型

不管是从计算成本，还是从易用性，还是从复用性，还是从一致性等等，我们都必须避免烟囱式的开发模式，而是以中间层的方式建设仓配实时数仓。与离线中间层基本一致，我们将实时中间层分为两层。

为了更有效地组织和管理数据，数仓建设往往会进行数据分层，一般自下而上分为四层。

对于存储层会依据不同的数据层的特点选择不同的存储介质

### ODS 操作数据层

#### 目标

ODS 层存储原始数据：

业务交互数据：

- 业务流程中产生的登录、订单、用户、商品、支付等相关的数据，通常存储在 DB 中，包括 MySQL，Oracle 等。
- MySQL BinLog 通过 Canal 传输至 Kafka。
- Kafka 主题命名 ODS_ORDER_INFO、ODS_ORDER_DETAIL、ODS_USER_INFO...

埋点用户行为数据：

- 用户在使用 Web、微信小程序产品过程中，与网站或小程序交互过程中产生的数据，比如页面浏览、点击、停留、评论、点赞、收藏等。
- 从业务集群通过 FLume 传输至大数据集群的 Kafka 中。
- Kafka 主题命名 ODS_LOG

Kafka 同时是实时和离线数据的数据源，离线数仓需要先从 Kafka 导入 Flume 写入 HDFS，从而进入离线数仓的 ODS 层；而对于实时数仓来说，Kafka 中的各个 Topic 中的数据可以直接作为实时数仓的 ODS 层。

#### 存储

ODS 层都是存储的一些实时数据，选择的是 Kafka 进行存储。

### DWD 数据明细层 、DIM 维度表

#### 目标

对 ODS 层数据进行清洗（去除空值，数据脱敏，脏数据，异常值），多数据源 join 维度退化，流式数据与离线维度信息等的组合，将一些相同粒度的业务系统、维表中的维度属性全部关联到一起，增加数据易用性和复用性，得到最终的实时明细数据。这部分数据有两个分支，一部分直接落地到 ADS，供实时明细查询使用，一部分再发送到消息队列中，供下层计算使用；

行为数据处理：

通过 Flink Streaming API， 提取 JSON 对象，将 JSON 对象根据字段封装成不同的样例类，并以 JSON 形式写入 Kafka 作为 DWD 层的行为数据。

- RT_DWD_START、RT_DWD_PAGE、RT_DWD_ACTION、RT_DWD_DISPLAY、RT_DWD_ERROR

维度表：

维度数据从 ODS 层相关主题读取至 Flink，将数据写入 HBase 或 Redis 方便实时查询。

- RT_XXXX

#### 存储

- DWD层都是存储的一些实时数据，选择的是Kafka进行存储，在DWD层会关联一些历史明细数据，会将其放到Redis里面。
- 在 DIM 层主要做一些高并发维度的查询关联，一般将其存放在 HBase 或 Tair 等 KV 里面。



### ODS 汇总层

- 比如日活 UV，从 DWD 层读取相关 RT_DWD_START 主题的数据，提取 JSON 对象，如果在 Spark Streaming 中，对数据进行批次间和同批次去重；如果是 Flink 利用状态函数变成进行去重，去重后的数据以样例类写入 HBase。之后应用层或 ADS 层通过统一查询接口，利用 MyBatis 进行汇总查询，对接前端汇总表进行大屏展示。

- 比如 GMV，从 ODS_
- 比如优惠券预警信息，从 DWD 层读取 RT_DWD_ACTION 主题的数据，提取 JSON 对象，根据业务需求开窗汇总，生成预警日志写入 ES，直接由 Kibana 创建 Dashboard 然后进行预警信息大屏输出。

#### 目标

DWS 公共实时汇总层以数据域+业务域的理念建设公共汇总层，与离线数仓不同的是，这里汇总层分为**轻度汇总层**和**高度汇总层**，并同时产出，轻度汇总层写入 ADS，用于前端产品复杂的 olap 查询场景，满足自助分析和产出报表的需求；高度汇总层写入 Hbase，用于前端比较简单的 kv 查询场景，提升查询性能，比如实时大屏等；（离线）ADS 为各种统计报表提供数据

注：

- ADS 是一款提供 OLAP 分析服务的引擎。开源提供类似功能的有，Elastic Search、Kylin、Druid 等；
- 案例中选择把数据写入到 Hbase 供 KV 查询，也可根据情况选择其他引擎，比如数据量不多，查询压力也不大的话，可以用 MySQL；
- 因主题建模与业务关系较大，这里不做描述；

#### 存储

对于DM层比价复杂，需要综合考虑对于数据落地的要求以及具体的查询引擎来选择不同的存储方式。对于常见的指标汇总模型直接放在MySQL里面，维度比较多的、写入更新比较大的模型会放在HBase里面，还有明细数据需要做一些多维分析或者关联会将其存储在Greenplum里面，还有一种是维度比较多、需要做排序、查询要求比较高的，如活动期间用户的销售列表等大列表直接存储在Redis里面。

### 应用层

即时查询主要通过 Flink， Presto、Hive 和 Spark 实现。



# 其他实践

1. [基于 Flink 的严选实时数仓实践](https://www.codercto.com/a/47662.html)

2. [「回顾」基于Flink的严选实时数仓实践](https://mp.weixin.qq.com/s/6UFrWoGf2e6kVC5UAK1JIQ?hmsr=joyk.com&utm_source=joyk.com&utm_medium=referral)
3. [美团点评基于 Flink 的实时数仓建设实践](https://tech.meituan.com/2018/10/18/meishi-data-flink.html)

4. [基于 Flink 的严选实时数仓实践](https://www.infoq.cn/article/Lrg1J4*tWOak2WLqKyhF)

5. [基于Flink的实时数据仓库实践分享](https://cloud.tencent.com/developer/article/1467820)

6. [知乎实时数仓实践及架构演进](https://zhuanlan.zhihu.com/p/56807637)

7. [大数据系统的Lambda架构](https://www.cnblogs.com/cciejh/p/lambda-architecture.html)

